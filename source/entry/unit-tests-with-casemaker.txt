title: Unit Tests with Casemaker
date: 2010-06-17
tags: testing, python
published: False
---
<p><span class="preamble">As far as I'm concerned, <a href="http://en.wikipedia.org/wiki/Unit_testing">unit testing</a> is a giant pain in the ass, but it's undeniably useful and needed in rapidly changing codebases, so long as the tests provide adequate test coverage.
</span></p>

<p>
So, what makes it a pain in the ass? Well, for starters, most people don't get off on coming up with potential holes or edge cases in code they write, and writing tests is almost never as exciting as the actual problem being solved, so they're seen as "work," and not fun, or exploration.
</p>

<p><a href="http://en.wikipedia.org/wiki/Test_Driven_Development">Test-driven Development</a>, or TDD for short, attempts to address the issue by creating the tests up front before you write <em>any</em> implementation details. Simiarly, <a href="http://en.wikipedia.org/wiki/Behavior_driven_development">Behavior-driven Development</a>, or BDD for short, is sort of complimentary to TDD, but tests are written in a more easy to read format, often plain English. There has been lots of studies that say that these techniques lead to larger test suites, which <em>could</em> lead to better code overall, and better productivity, which I don't find fault with. What I do find fault with is that it is often used to define the <em>design</em> of the code.</p>

<p>A great example of this is the classic case of Ron Jeffries vs. Peter Norvig in "Sudoku the Battle." If you're not familiar, <a href="http://www.xprogramming.com/xpmag/OkSudoku.htm">here</a>,<a href="http://www.xprogramming.com/xpmag/Sudoku2.htm"> here</a>, <a href="http://www.xprogramming.com/xpmag/SudokuMusings.htm">here</a>, <a href="http://www.xprogramming.com/xpmag/Sudoku4.htm">here</a> and <a href="http://www.xprogramming.com/xpmag/sudoku5.htm">here</a> vs. <a href="http://norvig.com/sudoku.html">here</a>.</p>

<p>What you'll notice pretty quickly is that Jefferies doesn't really <em>think</em> about the solution, but writes code that will <em>verify</em> it's correct when he comes across it. Norvig on the other hand, actively <em>thinks</em> about the solution, fiddles with some ideas and comes up with a robust solver in 100 lines of code.</p>

<p>I don't wanna start some sort of flame war or debate on which one works better, because I'm already getting off topic, but my preference happens to be the Norvig approach. I like to think about a problem, do some exploration in a <a href="http://en.wikipedia.org/wiki/Read-eval-print_loop">REPL</a> and build a solution. Incidentally, in doing so, I often end up with a mostly correct solution and some unit tests to start with. I can then build out some more tests for better edge case checking and things of that nature.</p>

<p>So, now I've got some basic functionality, a unit if you will, and a <em>few</em> tests that I've run to verify it seems to be working. What next? I need more tests which test edge cases and invalid input.</p>

<p>I'm lazy though, and these sorts of things aren't necessarily fun to write. Copy and paste is an option, but that leads to more verbosity to wade through later for not much benefit. Consider the following code sample:</p>

<p>




Generating lots of test cases... quikchek, paycheck, *check

Nose has a solutiion where you yield an iterable... 

I have a solution where you explicitly write the function, and blah.

In no way do I think this is ultimately the best way to do things, but it's certainly "a way"

What do you think? 

